{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture 3 - Manipulating Data Frames and Calculating Summaries"
      ],
      "metadata": {
        "id": "A_Ji-qP20qEv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Today's Key Takeaways\n",
        "\n",
        "- **Reshaping** data frames\n",
        "- Calculating **summary parameters**\n",
        "- **Sorting** data in `pandas`"
      ],
      "metadata": {
        "id": "VyKb_WvH0sz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding libraries to python\n",
        "\n",
        "First we need to import the libraries that we'll want to use for today's class. This is the same process you used for the last homework to add a function to python, but libraries can add hundreds of new functions.\n",
        "\n",
        "When we import these libraries we can assign them an alias, which is easier to remember and type. The ones used below are common for these packages. "
      ],
      "metadata": {
        "id": "f91VJN7m1W1w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lEqd_sPyW5f"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### From Last Time:\n",
        "\n",
        "Start by importing the metadata (same as last week)."
      ],
      "metadata": {
        "id": "JTO7ITsN1fHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative way to bring in Data\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "rnKkzvMJpMf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bring in metadata\n",
        "CountsData = pd.read_csv(\"melanoma_CountsRaw.csv\", index_col=0)\n",
        "CountsData.head()\n"
      ],
      "metadata": {
        "id": "pLLnH9SBpeWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subsetting\n",
        "\n",
        "One of the powerful features of data frames is that rows and columns can be referred to by names or numbers:"
      ],
      "metadata": {
        "id": "NA1zDBKJKD9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CountsData['Stage']"
      ],
      "metadata": {
        "id": "Iz_ZbEz4Qgr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To select multiple rows or columns, input a list:"
      ],
      "metadata": {
        "id": "r1E7joM2KJ-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CountsData.loc[['FM_1','FM_2','FM_3'],'Stage']"
      ],
      "metadata": {
        "id": "AksnbyX3J6Nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also subset data by number by using \"`.iloc`\" (zero-indexing also applies here)"
      ],
      "metadata": {
        "id": "EalKz4AlKOyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CountsData.iloc[0:3,2]"
      ],
      "metadata": {
        "id": "q3JlUKuaKMJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data frames can also be sliced by rows without explicitly naming the row names or row numbers. Instead, we can slice by testing whether a condition is fulfilled or not:"
      ],
      "metadata": {
        "id": "vkhfq0LFKXty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding out which rows match the stage: \"primary melanocytes\"\n",
        "primary_indices = CountsData.Stage == 'primary melanocytes'\n",
        "print(primary_indices)"
      ],
      "metadata": {
        "id": "WlziiRZvryP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# subsetting the rows based on this conditional set\n",
        "primary_melanocytes_data = CountsData[primary_indices]\n",
        "primary_melanocytes_data"
      ],
      "metadata": {
        "id": "FqBXRZgir0OA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=blue> Optional Bonus: Data Manipulation - adding new columns to data frames \n",
        "\n",
        "We can add a new column to a data frame using the same syntax as assigning a column slice to a data structure that contains the same number of elements as rows in the data frame. "
      ],
      "metadata": {
        "id": "pJdapEL81jVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find out the number of rows and columns with the .shape attribute\n",
        "CountsData.shape"
      ],
      "metadata": {
        "id": "r9xmjsDB1lFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`CountsData` has 12 rows and 35,243 columns. So say we want to add an extra column to `CountsData` that includes the replicate number for each sample (i.e. either 1, 2, or 3).\n",
        "\n",
        "There are multiple ways of doing this, but one of the ways would be to create a list that looks like [1,2,3,1,2,...].\n",
        "\n",
        "We can do this by first creating a `numpy` array that contains the numbers 1-3, convert it to a list, then use list operations to duplicate it 3 more times. We can then assign this to a new column in the `CountsData` data frame, that we'll call `replicate_number`."
      ],
      "metadata": {
        "id": "PNxFumqA1nce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a numpy array of that starts from 1 and ends before 4, stepping by 1, using the np.arange() function.\n",
        "tmp =  np.arange(1,4)\n",
        "print(tmp)\n",
        "\n"
      ],
      "metadata": {
        "id": "r38FUIns1oC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting to a list\n",
        "tmp = tmp.tolist()\n",
        "\n",
        "# Duplicating the list three additional times\n",
        "tmp = tmp * 4\n",
        "print(tmp)"
      ],
      "metadata": {
        "id": "fhaGivWNhjpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning a new column called 'sample_number' in the data frame meta with the values in tmp\n",
        "CountsData['replicate_number'] = tmp\n",
        "CountsData.head()"
      ],
      "metadata": {
        "id": "VspWJfdr1rR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can rearrange the column order so that the replicate number is more visible during `.head()` calls. Other examples of how to do this can be found [here](https://stackoverflow.com/questions/13148429/how-to-change-the-order-of-dataframe-columns) and [here](https://stackoverflow.com/questions/53141240/pandas-how-to-swap-or-reorder-columns)."
      ],
      "metadata": {
        "id": "R9V-Mlx013nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = CountsData.columns.tolist() # Extract the column names and save it as a list.\n",
        "print(cols)\n",
        "print(len(cols)) # Sanity check: print out number of columns"
      ],
      "metadata": {
        "id": "uyj-1IQsk4fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colsRearranged = cols[:3] + cols[-1:] + cols[3:-1] # Use list operations to rearrange the order of the columns\n",
        "print(colsRearranged)\n",
        "print(len(colsRearranged)) # Sanity check: print out number of rearranged columns"
      ],
      "metadata": {
        "id": "MkYgTYwIlDjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CountsData = CountsData[colsRearranged] # Slice the data frame by the rearranged column order, and then save it as the rearranged data frame\n",
        "CountsData.head()"
      ],
      "metadata": {
        "id": "wwIWH0mmlxT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Manipulation - removing columns with low counts by conditional slicing\n",
        "\n",
        "Often times when working with high-throughput experimental data, there will be specific columns (corresponding to variables) that we won't want to consider, because those columns contain data that don't pass a particular inclusion criteria. This case study (removing columns with low counts), will show how to remove the columns that don't pass the inclusion criteria from the data frame without having to know beforehand which column numbers they are. \n",
        "\n",
        "To start, we'll first create a variable that only stores the subset of the data frame that contains the expression count data."
      ],
      "metadata": {
        "id": "3sbOTGc35YxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataExp = CountsData.loc[:,'A1BG':]\n",
        "dataExp.head()"
      ],
      "metadata": {
        "id": "Qy5U5XsBo82d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a Data Frame of boolean values showing where there are read counts less than 1\n",
        "df_low = dataExp < 1\n",
        "df_low"
      ],
      "metadata": {
        "id": "-fyZYtaZ5seB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add together all of the columns to get total number of samples with low counts\n",
        "lowsum = df_low.sum()\n",
        "lowsum.head()"
      ],
      "metadata": {
        "id": "bsF3p8K55wPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Showing which samples have low expression of the gene A1CF\n",
        "df_low.A1CF"
      ],
      "metadata": {
        "id": "gOaM73r85yRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subsetting the expression matrix on the samples deemed to be low in A1CF expression.\n",
        "dataExp.loc[df_low.A1CF,'A1CF']"
      ],
      "metadata": {
        "id": "YgrI5BNP6MWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To help us get a sense of the distribution of the `lowsum` variable, we can use `pandas` calculation of summary parameters using the `.describe()` method. "
      ],
      "metadata": {
        "id": "RIDv0Hn559M5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at the quantiles\n",
        "lowsum.describe()"
      ],
      "metadata": {
        "id": "Aa01_iTd6CBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see that many genes either have reads for all 12 samples or none of them. We want to remove all of those genes from our data frame. Let's do that by selecting on a list of genes that have reads for all 12 samples."
      ],
      "metadata": {
        "id": "CbEn85Sb8C5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a mask of all the columns we want to keep\n",
        "# Let's be picky and only accept genes where all 12 samples have counts\n",
        "keep = lowsum < 1\n",
        "keep.head()"
      ],
      "metadata": {
        "id": "VA7uy3gE8H6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating how many are have reads for all 12 samples\n",
        "np.sum(keep)"
      ],
      "metadata": {
        "id": "lC-TnmMV8JtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using df.loc we can select just the genes we want to keep\n",
        "Exp_low_removed = dataExp.loc[:,keep]"
      ],
      "metadata": {
        "id": "pTbGDS7q8Lbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape before and after\n",
        "print(dataExp.shape)\n",
        "print(Exp_low_removed.shape)"
      ],
      "metadata": {
        "id": "I_VSVGnP8Ngn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Exp_low_removed.head()"
      ],
      "metadata": {
        "id": "DCJjfAS68Q0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=brown>Hands on practice</font>\n",
        "How many genes have less than 12 samples with reads, but more than zero?"
      ],
      "metadata": {
        "id": "98e2jKEh8UCU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xsGkS5_j8XA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Manipulation: log2-transform expression counts\n",
        "\n",
        "Another useful manipulation of data is to apply a mathematical operation uniformly across all of the values in a dataset. In this case study, we're going to apply the log2 transformation."
      ],
      "metadata": {
        "id": "PR25bSe_8hqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the log2 transformation\n",
        "Exp_low_removed_log2 = np.log2(Exp_low_removed)\n",
        "Exp_low_removed_log2.head()"
      ],
      "metadata": {
        "id": "gXbYsV9k9yyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Manipulation: Joining data frames\n",
        "\n",
        "Let's join the `meta` data frame with the `df` data frame. To do this, we will use the `pandas` function `pd.concat()`. Note that this works similarly to `.hstack()` and `.vstack()` from numpy, but you must specify which axis to concatenate (0 = stitch by rows, equivalent to `vstack`, 1 = stitch by columns, equivalent to `hstack`). "
      ],
      "metadata": {
        "id": "SvER0KZeXPqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meta = CountsData.loc[:,:'cell_line']\n",
        "meta.head()"
      ],
      "metadata": {
        "id": "jXNxAcpPq0fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the two data frames with concat\n",
        "melanoma_log2 = pd.concat([meta,Exp_low_removed_log2],axis = 1)"
      ],
      "metadata": {
        "id": "bYrkv3RCXUWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the dimensions and show the first few lines of the new data frame\n",
        "melanoma_log2.shape\n",
        "melanoma_log2.head()"
      ],
      "metadata": {
        "id": "Y-L0brcHXaVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's export this data frame to excel, so that we can directly import this data frame in future classes."
      ],
      "metadata": {
        "id": "ChRR_6JAXkRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# export to excel, including the index column\n",
        "melanoma_log2.to_excel('melanoma_zerosRemoved_log2transformed_2023.xlsx',index = True)"
      ],
      "metadata": {
        "id": "kwhu74JiXzlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating Summary Parameters\n",
        "\n",
        "`pandas` also enables calculation of summary parameters using the `.describe()` method (reference [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html)). Note that this will only work effectively for small data frames, so in this example, we are only looking at the first 10 genes of `df_low_removed_log2` (we're using `df_low_removed_log2` instead of `melanoma_log2` because it doesn't have the metadata columns): "
      ],
      "metadata": {
        "id": "uZ1F0_NtX0JG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "melanoma_log2.loc[:,'A1BG':'AACS'].describe()"
      ],
      "metadata": {
        "id": "-78CymenX9lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also customize what your summary statistics will consist of with the `.aggregate()` method (reference [here](https://www.geeksforgeeks.org/python-pandas-dataframe-aggregate/) and [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.aggregate.html)). "
      ],
      "metadata": {
        "id": "vmFZFlPQX89t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the minimum, median, max, and sum across rows of each column. \n",
        "# Note that the median function is found in numpy.\n",
        "melanoma_log2.loc[:,'A1BG':'AACS'].aggregate([min,np.median,max,sum])"
      ],
      "metadata": {
        "id": "_dj-ZLfkYHBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The set of aggregate metrics that can be calculated are:\n",
        "\n",
        "- `mean` - the average\n",
        "- `median` - the median\n",
        "- `prod` - the product\n",
        "- `sum` - the sum\n",
        "- `std` - the standard deviation\n",
        "- `var` - the variance"
      ],
      "metadata": {
        "id": "qFkdfafhYKnK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating overall metrics and sorting\n",
        "\n",
        "For each of the metrics that you can use with `.aggregate()` (e.g. `df.mean()`, `df.min()`, etc.), you can calculate them individually.  \n",
        "\n",
        "This is particularly useful when you want to find genes that are doing interesting things in your data."
      ],
      "metadata": {
        "id": "Cig_IlBSZeUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the overall variance with df.var() \n",
        "overall_variance = melanoma_log2.loc[:,'A1BG':].var()\n",
        "print(overall_variance.head())\n",
        "print(overall_variance.shape)"
      ],
      "metadata": {
        "id": "JhgB0dr6YJZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Case study**: we want to find genes that are highly variable across conditions, but we don't know which they are. Therefore, we're going to sort the overall variance values that we just calculated in descending order (i.e. from largest to smallest) using the `.sort_values()` method. Then, we'll be able to pick out which genes are the most variable"
      ],
      "metadata": {
        "id": "LQyy5qwhZt4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort this Series and select the 20 genes with the largest variance\n",
        "overall_variance.sort_values(inplace = True, ascending= False)\n",
        "overall_variance.head()"
      ],
      "metadata": {
        "id": "OxXwV6QSZvtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the `overall_variance` variable has changed, even though we haven't reassigned it (with the = sign). This is because we set the `.sort_values()` argument `inplace = True`. "
      ],
      "metadata": {
        "id": "OR3I5mV1ZyEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now print the top 10 most variable genes.\n",
        "topvar = overall_variance[:10]\n",
        "print(topvar)\n",
        "type(topvar)"
      ],
      "metadata": {
        "id": "2FF7rGHqZ07h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can pull out the gene information by accessing the `index` attribute of this `pandas series`:"
      ],
      "metadata": {
        "id": "4O4aNVvxb8dc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We want to use the gene names, not their variance, to filter the columns of melanoma_log2\n",
        "topvar.index"
      ],
      "metadata": {
        "id": "YAIgatHsb92_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then use these indexes to slice the `melanoma_df` data frame and look at what the actual expression count values were for these genes."
      ],
      "metadata": {
        "id": "tAN6bPYlb_tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we can use that Series with melanoma_log.loc to make a subtable\n",
        "topvartable = melanoma_log2.loc[:,topvar.index]\n",
        "topvartable"
      ],
      "metadata": {
        "id": "avMZ7cUycBOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computation based on sample groups \n",
        "\n",
        "Our expression dataset has three replicates for each cell line. `pandas` enables calculation of multiple paramaters with these replicates consolidated, if your input data frame contains a variable that contains the grouping information. \n",
        "\n",
        "The replicates can be grouped together with the syntax:\n",
        "```python \n",
        "df.groupby(['column_name'])\n",
        "```"
      ],
      "metadata": {
        "id": "piqX1t0mcFb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reminder of what melanoma_log2 looks like\n",
        "melanoma_log2.head()"
      ],
      "metadata": {
        "id": "3TAsy5PGcG9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using .groupby() to designate groupings by cell line\n",
        "mel_by_cel = melanoma_log2.groupby('cell_line')\n",
        "mel_by_cel"
      ],
      "metadata": {
        "id": "43PWzYmPcKF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have made a \"`DataFrameGroupBy`\" object.\n",
        "\n",
        "This is an iterator, an object that iterates over a function, offering it one block of data at a time. To generate the mean of each gene for each cell line, we use the following:"
      ],
      "metadata": {
        "id": "Dk9Y454dcV-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculates group-by mean\n",
        "mel_by_cel_mean = mel_by_cel.mean()\n",
        "mel_by_cel_mean"
      ],
      "metadata": {
        "id": "fS-C3w1ZcZ9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculates group-by variance\n",
        "mel_by_cel_var = mel_by_cel.var()\n",
        "mel_by_cel_var"
      ],
      "metadata": {
        "id": "O7hULJx9ccgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " We can similarly calculate the `median`, `min`, `max`, `var`, and a host of other metrics."
      ],
      "metadata": {
        "id": "A1PkalX6chPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=brown>Hands on practice</font>\n",
        "1. Use `groupby` to calculate the mean expression counts across each stage.\n",
        "2. Use `describe` to calculate the summary parameters of `mean_bystage` for the metastatic and primary melanocytes stages separately.\n",
        "3. Find the top 10 variably expressed gene between the stages from the `mean_bystage` variable.\n",
        "4. Display the `mean_bystage` table sliced to show only these top 10 genes."
      ],
      "metadata": {
        "id": "PjDzlpnVcpeO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e3qJIsFocwdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VGtqLruscxTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ynj1bFI_cxH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Et4MZucpcw5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For more information about grouping, summarization, and aggregation, [go here](https://jakevdp.github.io/PythonDataScienceHandbook/03.08-aggregation-and-grouping.html)."
      ],
      "metadata": {
        "id": "S3BasLfZcxwD"
      }
    }
  ]
}